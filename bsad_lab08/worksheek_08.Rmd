---
title: "Business Analytics Lab Workshop 8"
author: "Kajal Chokshi"
date: "June 8th 2017"
output:
  html_notebook: default
  html_document: default
  pdf_document: default
subtitle: CME Group Foundation Business Analytics Lab
---

###About

Predictive Modeling is a process that uses data mining and probability to forecast outcomes. This idea is incredibly powerful because, if done well, it can be used to predict sales for the next quarter, stock prices, the usefulness of marketing, or anything else really. These predictive models are each made up of a number of predictors, which are variables that are likely to influence future results. Once data has been collected for relevant predictors, a statistical model is formulated.

The best way to create a predictive model is to begin with a complete data set. Split the data however you please into two sets: the training set and the testing set. In this case, lets let the training data set be 70% of the dataset and the testing dataset be the remaining 30% of the data. We take the training set and build a model that fits the data. Lastly, we test the model on the testing data set and see how close we were to the actual values.

This concept might seem overwhelming, but we already have almost all of the tools to do this. Follow along carefully.

###SetUp
Make sure to download the folder titled 'bsad_lab8' zip folder and extract the folder to unzip it. Next, we must set this folder as the working directory. The way to do this is to open R Studio, go to 'Session', scroll down to 'Set Working Directory', and click 'To Source File Location'. Now, follow the worksheet directions to complete the lab.

----------

###Task 1

This first half will focus on the building models using the training data. The first step is to read in our training data. Make sure to view the data to ensure it is read in correctly. 

```{r}
traindata <- read.csv(file="data/creditscoretrain.csv", header=TRUE)
traindata
```

Next, we must extract the two columns so we can refer too them within the code easier. 
```{r}
age_train <- traindata$Age
rating_train <- traindata$Rating
```

Now, we will build our first model, a linear model. We learned this concept in worksheet 6. We will use the age variable to predict the rating. Make sure to find the summary statistics so we know how well the model is doing. Consider plotting the model similar to the way we did in worksheet 6 if you would like to also visualize the data.
```{r}
linear_train <- lm(rating_train ~ age_train)
summary(linear_train)
```

Lets build a non-linear model as well to see how it performs compared to the linear model. Refer to worksheet 6 for more details. The rating can be called the y, the response, or the dependent variable. The age is the x, the predictor, or the independent variable.

```{r}
age_train2<-age_train^2
quad_train<-lm(rating_train ~ age_train+age_train2) 
summary(quad_train)
```

With the linear model, the R-Squared value is 0.0263 and the Adj R-Squared value is -0.0278.
With the quadratic model, the R-Squared value is 0.2061 and the Adj R-Squared value is 0.1127.

The quadratic model is a better fit than the linear model, while both are not extraordinary. 

----------

###Task 2

The second half of predictive modeling centers around actually testing your model on the data set. For this, we must first read in our testing set. Make sure to view the dataset to ensure it is read propertly.

```{r}
testdata <- read.csv("data/creditscoretest.csv", header=TRUE)
testdata
```

Next, we must extract the variables as we always do. 

```{r}
age_test = testdata$Age
rating_test = testdata$Rating
```

Now, we must check if the models were actually good predictive models. We must calculate the predicted rating based on the training data of the linear model and the quadratic model.

```{r}
rating_predict1 <- coef(linear_train)[1]+coef(linear_train)[2]*age_test
```

Now, we will plot the testing data, predicted values and the age
```{r}
plot(age_test, rating_test)
par(new=TRUE, xaxt="n", yaxt="n", ann=FALSE)
plot(age_test,rating_predict1, col="red")
```
Now, plot the true values against the predicted values. 

```{r}
plot(rating_test, rating_predict1, xlab='Test', ylab='Predict', main='Linear')
```
Below, evaluate the goodness of your prediction by looking at a scatterplot of the testing/observed values, versus the predicted values generated by the model.

Next, calculate the predicted rating based on the training data non-linear quadratric model
```{r}
rating_predict2 = coef(quad_train)[1]+coef(quad_train)[2]*age_test+coef(quad_train)[3]*age_test^2
```

Now, plot the test, predictions and age. 
```{r}
plot(age_test, rating_test)
par(new=TRUE, xaxt="n", yaxt="n", ann=FALSE)
plot(age_test,rating_predict2, col="green")
```
Next, plot the true values against the predicted. 

```{r}
plot(rating_test, rating_predict2, xlab='Test', ylab='Predict', main='Quadratric')
```
Below, evaluate the goodness of your prediction by looking at a scatterplot of the testing/observed values, versus the predicted values generated by the model.

Based on the scatter plots which model is a better predictor? 

Lastly, to quantify the results, we calculate the root mean square error.
```{r}
#Error for Linear Model
error1=sum(rating_predict1-rating_test)/length(rating_test)
rmse1=sqrt(error1)
rmse1

#Error for Quadratic Model
error2=sqrt(sum(rating_predict2-rating_test)^2)/length(rating_test)
rmse2=sqrt(error2)
rmse2
```
Based on the root mean square error (RMSE) calculations which model is better? How do results reconcile with the results from Task 1?
